{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Information\n",
    "\n",
    "Name: Amie Davis\n",
    "\n",
    "Course: DSC630 - Predictive Analytics\n",
    "\n",
    "Assignment Number: Final Project Part 3\n",
    "\n",
    "Purpose: Build model(s)\n",
    "\n",
    "Usage: Python 3.7.6\n",
    "\n",
    "   Developed using Jupter Notebook 6.0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source\n",
    "Uniform Crime Reporting Program Data: National Incident-Based Reporting System, [United States], 2016; United States Federal Bureau of Investigation; Inter-university Consortium for Political and Social Research (ICPSR), University of Michigan; https://www.icpsr.umich.edu/icpsrweb/NACJD/NIBRS/ \n",
    "\n",
    "\n",
    "Geodetic Data for US Cities: https://simplemaps.com/data/us-cities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "\n",
    "In Part 3, I will build a decision tree classification model to predict the type of offenses committed, given location information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress Warnings\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore') \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (7,11,14,15,16,17,18,19,41,42,44,46,51,52,53,54,56) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load data into dataframe\n",
    "data_file = \"Data\\crime_offenses_top6.csv\"    # Data from Top 6 States\n",
    "#data_file = \"Data\\crime_offenses_all.csv\"    # Data from All States\n",
    "df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'X1', 'ORI', 'INC_NUM', 'VIC_INC_DATE', 'VICTIM_TYPE',\n",
      "       'ACT_TYPE_OFFC', 'ASSG_TYPE_OFFC', 'AGE_OF_VICTIM', 'SEX_OF_VICTIM',\n",
      "       'RACE_OF_VICTIM', 'ETHNIC_OF_VIC', 'VIC_RESIDENT', 'ASSAULT_CIRC1',\n",
      "       'ASSAULT_CIRC2', 'JUST_HOM_CIRC', 'INJURY_TYPE1', 'INJURY_TYPE2',\n",
      "       'INJURY_TYPE3', 'INJURY_TYPE4', 'INJURY_TYPE5', 'NUM_RECS_PER_VICTIM',\n",
      "       'VIC_INC_YEAR', 'VIC_INC_MONTH', 'VIC_INC_DAY', 'VIC_INC_DOW',\n",
      "       'NUM_STATE_CODE', 'CITY', 'STATE', 'POP_GROUP', 'CTRY_DIVISION',\n",
      "       'CTRY_REGION', 'AGENCY_IND', 'CORE_CITY', 'FBI_OFFICE', 'JUDICIAL_DIST',\n",
      "       'CURRENT_POP1', 'UCR_COUNTY_CD1', 'MSA_CD1', 'LAST_POP1',\n",
      "       'FIPS_COUNTY1', 'city_ascii', 'state_name', 'county_fips',\n",
      "       'county_name', 'county_fips_all', 'county_name_all', 'lat', 'lng',\n",
      "       'population', 'density', 'source', 'military', 'incorporated',\n",
      "       'timezone', 'ranking', 'zips', 'id', 'OFF_CODE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove irrelevant and redundant fields\n",
    "\n",
    "# Drop unneeded columns\n",
    "df.drop(['X1','id', 'county_fips', 'county_fips_all', 'Unnamed: 0', \n",
    "         'ORI', 'INC_NUM', 'NUM_RECS_PER_VICTIM', 'VIC_INC_DATE', 'VIC_INC_YEAR', 'VIC_INC_DAY',\n",
    "         'ASSAULT_CIRC1', 'ASSAULT_CIRC2', 'JUST_HOM_CIRC', \n",
    "         'INJURY_TYPE1', 'INJURY_TYPE2', 'INJURY_TYPE3',\n",
    "         'INJURY_TYPE4', 'INJURY_TYPE5', 'NUM_RECS_PER_VICTIM',\n",
    "         'FBI_OFFICE', 'JUDICIAL_DIST', 'FIPS_COUNTY1',\n",
    "         'LAST_POP1', 'UCR_COUNTY_CD1', 'MSA_CD1', 'city_ascii', 'CITY', 'STATE',\n",
    "         'state_name', 'county_name', 'county_name_all', 'population', 'zips',\n",
    "         'source'], \n",
    "        axis=1, inplace = True)\n",
    "\n",
    "# Keep AGENCY_IND\n",
    "\n",
    "# Also removing victim demograohics since they are not relevant to predict offenses and locations\n",
    "#df.drop(['VICTIM_TYPE','RACE_OF_VICTIM', 'AGE_OF_VICTIM', \n",
    "#         'SEX_OF_VICTIM', 'ETHNIC_OF_VIC', 'VIC_RESIDENT'],\n",
    "#        axis=1, inplace = True)\n",
    "\n",
    "# Verify Change\n",
    "#print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NA values with UNKNOWN\n",
    "#df.replace('NA', 'U')\n",
    "\n",
    "# Drop columns with mostly NULL data\n",
    "df.drop(['ACT_TYPE_OFFC','ASSG_TYPE_OFFC','CORE_CITY'],\n",
    "        axis=1, inplace = True)\n",
    "\n",
    "# Drop records with remaining null values\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find null records\n",
    "#count_nan_in_df = df.isnull().sum()\n",
    "#print (count_nan_in_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VICTIM_TYPE</th>\n",
       "      <th>AGE_OF_VICTIM</th>\n",
       "      <th>SEX_OF_VICTIM</th>\n",
       "      <th>RACE_OF_VICTIM</th>\n",
       "      <th>ETHNIC_OF_VIC</th>\n",
       "      <th>VIC_RESIDENT</th>\n",
       "      <th>VIC_INC_MONTH</th>\n",
       "      <th>VIC_INC_DOW</th>\n",
       "      <th>NUM_STATE_CODE</th>\n",
       "      <th>POP_GROUP</th>\n",
       "      <th>...</th>\n",
       "      <th>AGENCY_IND</th>\n",
       "      <th>CURRENT_POP1</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>density</th>\n",
       "      <th>military</th>\n",
       "      <th>incorporated</th>\n",
       "      <th>timezone</th>\n",
       "      <th>ranking</th>\n",
       "      <th>OFF_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>43974.0</td>\n",
       "      <td>41.6722</td>\n",
       "      <td>-70.3599</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>43974.0</td>\n",
       "      <td>41.6722</td>\n",
       "      <td>-70.3599</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>43974.0</td>\n",
       "      <td>41.6722</td>\n",
       "      <td>-70.3599</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>43974.0</td>\n",
       "      <td>41.6722</td>\n",
       "      <td>-70.3599</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>43974.0</td>\n",
       "      <td>41.6722</td>\n",
       "      <td>-70.3599</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    VICTIM_TYPE  AGE_OF_VICTIM  SEX_OF_VICTIM  RACE_OF_VICTIM  ETHNIC_OF_VIC  \\\n",
       "0             0             27              1               0              0   \n",
       "1             0             25              1               0              1   \n",
       "2             0             51              2               0              1   \n",
       "4             0             50              2               0              0   \n",
       "21            0             30              1               0              2   \n",
       "\n",
       "    VIC_RESIDENT  VIC_INC_MONTH  VIC_INC_DOW  NUM_STATE_CODE  POP_GROUP  ...  \\\n",
       "0              1              1            6              20        4.0  ...   \n",
       "1              2              1            6              20        4.0  ...   \n",
       "2              2              1            6              20        4.0  ...   \n",
       "4              1              1            7              20        4.0  ...   \n",
       "21             2              1            6              20        4.0  ...   \n",
       "\n",
       "    AGENCY_IND  CURRENT_POP1      lat      lng  density  military  \\\n",
       "0            1       43974.0  41.6722 -70.3599    284.0         0   \n",
       "1            1       43974.0  41.6722 -70.3599    284.0         0   \n",
       "2            1       43974.0  41.6722 -70.3599    284.0         0   \n",
       "4            1       43974.0  41.6722 -70.3599    284.0         0   \n",
       "21           1       43974.0  41.6722 -70.3599    284.0         0   \n",
       "\n",
       "    incorporated  timezone  ranking  OFF_CODE  \n",
       "0              1         1      2.0       261  \n",
       "1              1         1      2.0       237  \n",
       "2              1         1      2.0       133  \n",
       "4              1         1      2.0       290  \n",
       "21             1         1      2.0       114  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change DOW to numeric value\n",
    "def f_dow(df):\n",
    "    if df['VIC_INC_DOW'] == 'Sunday':\n",
    "        val = 1\n",
    "    elif df['VIC_INC_DOW'] == 'Monday':\n",
    "        val = 2\n",
    "    elif df['VIC_INC_DOW'] == 'Tuesday':\n",
    "        val = 3\n",
    "    elif df['VIC_INC_DOW'] == 'Wednesday':\n",
    "        val = 4\n",
    "    elif df['VIC_INC_DOW'] == 'Thursday':\n",
    "        val = 5\n",
    "    elif df['VIC_INC_DOW'] == 'Friday':\n",
    "        val = 6\n",
    "    elif df['VIC_INC_DOW'] == 'Saturday':\n",
    "        val = 7\n",
    "    else:\n",
    "        val=0\n",
    "    return val\n",
    "\n",
    "# Change Timezone to numeric value\n",
    "def f_tz(df):\n",
    "    if df['timezone'] == 'America/New_York':\n",
    "        val = 1\n",
    "    elif df['timezone'] == 'America/Detroit':\n",
    "        val = 2\n",
    "    elif df['timezone'] == 'America/Chicago':\n",
    "        val = 2\n",
    "    elif df['timezone'] == 'America/Denver':\n",
    "        val = 3\n",
    "    elif df['timezone'] == 'America/Los_Angeles':\n",
    "        val = 4\n",
    "    else:\n",
    "        val=0\n",
    "    return val\n",
    "\n",
    "# Convert simple categorical features to numeric to limit dummy features\n",
    "df['VIC_INC_DOW'] = df.apply(f_dow, axis=1)\n",
    "df['timezone'] = df.apply(f_tz, axis=1)\n",
    "\n",
    "df['SEX_OF_VICTIM'] = df['SEX_OF_VICTIM'].map({'M': 2, 'F': 1, 'U': 0})\n",
    "df['ETHNIC_OF_VIC'] = df['ETHNIC_OF_VIC'].map({'H': 2, 'N': 1, 'U': 0})\n",
    "df['VIC_RESIDENT'] = df['VIC_RESIDENT'].map({'R': 2, 'N': 1, 'U': 0})\n",
    "#df['CORE_CITY'] = df['CORE_CITY'].map({'Y': 1, 'N': 0})\n",
    "df['military'] = df['military'].map({True: 1, False: 0})\n",
    "df['incorporated'] = df['incorporated'].map({True: 1, False: 0})\n",
    "\n",
    "# Change target feature to easily translated numeric values\n",
    "def f_off(df):\n",
    "    if df['OFF_CODE'] == '09A':\n",
    "        val = 91\n",
    "    elif df['OFF_CODE'] == '09B':\n",
    "        val = 92\n",
    "    elif df['OFF_CODE'] == '09C':\n",
    "        val = 93\n",
    "    elif df['OFF_CODE'] == '100':\n",
    "        val = 100\n",
    "    elif df['OFF_CODE'] == '11A':\n",
    "        val = 111\n",
    "    elif df['OFF_CODE'] == '11B':\n",
    "        val = 112\n",
    "    elif df['OFF_CODE'] == '11C':\n",
    "        val = 113\n",
    "    elif df['OFF_CODE'] == '11D':\n",
    "        val = 114\n",
    "    elif df['OFF_CODE'] == '120':\n",
    "        val = 120\n",
    "    elif df['OFF_CODE'] == '13A':\n",
    "        val = 131\n",
    "    elif df['OFF_CODE'] == '13B':\n",
    "        val = 132\n",
    "    elif df['OFF_CODE'] == '13C':\n",
    "        val = 133\n",
    "    elif df['OFF_CODE'] == '200':\n",
    "        val = 200\n",
    "    elif df['OFF_CODE'] == '210':\n",
    "        val = 210\n",
    "    elif df['OFF_CODE'] == '220':\n",
    "        val = 220\n",
    "    elif df['OFF_CODE'] == '23A':\n",
    "        val = 231\n",
    "    elif df['OFF_CODE'] == '23B':\n",
    "        val = 232\n",
    "    elif df['OFF_CODE'] == '23C':\n",
    "        val = 233\n",
    "    elif df['OFF_CODE'] == '23D':\n",
    "        val = 234\n",
    "    elif df['OFF_CODE'] == '23E':\n",
    "        val = 235\n",
    "    elif df['OFF_CODE'] == '23F':\n",
    "        val = 236\n",
    "    elif df['OFF_CODE'] == '23G':\n",
    "        val = 237\n",
    "    elif df['OFF_CODE'] == '23H':\n",
    "        val = 238\n",
    "    elif df['OFF_CODE'] == '240':\n",
    "        val = 240\n",
    "    elif df['OFF_CODE'] == '250':\n",
    "        val = 250\n",
    "    elif df['OFF_CODE'] == '26A':\n",
    "        val = 261\n",
    "    elif df['OFF_CODE'] == '26B':\n",
    "        val = 262\n",
    "    elif df['OFF_CODE'] == '26C':\n",
    "        val = 263\n",
    "    elif df['OFF_CODE'] == '26D':\n",
    "        val = 264\n",
    "    elif df['OFF_CODE'] == '26E':\n",
    "        val = 265\n",
    "    elif df['OFF_CODE'] == '26F':\n",
    "        val = 266\n",
    "    elif df['OFF_CODE'] == '26G':\n",
    "        val = 267\n",
    "    elif df['OFF_CODE'] == '270':\n",
    "        val = 270\n",
    "    elif df['OFF_CODE'] == '280':\n",
    "        val = 280\n",
    "    elif df['OFF_CODE'] == '290':\n",
    "        val = 290\n",
    "    elif df['OFF_CODE'] == '35A':\n",
    "        val = 351\n",
    "    elif df['OFF_CODE'] == '35B':\n",
    "        val = 352\n",
    "    elif df['OFF_CODE'] == '36A':\n",
    "        val = 361\n",
    "    elif df['OFF_CODE'] == '36B':\n",
    "        val = 362\n",
    "    elif df['OFF_CODE'] == '370':\n",
    "        val = 370\n",
    "    elif df['OFF_CODE'] == '39A':\n",
    "        val = 391\n",
    "    elif df['OFF_CODE'] == '39B':\n",
    "        val = 392\n",
    "    elif df['OFF_CODE'] == '39C':\n",
    "        val = 393\n",
    "    elif df['OFF_CODE'] == '39D':\n",
    "        val = 394\n",
    "    elif df['OFF_CODE'] == '40A':\n",
    "        val = 401\n",
    "    elif df['OFF_CODE'] == '40B':\n",
    "        val = 402\n",
    "    elif df['OFF_CODE'] == '40C':\n",
    "        val = 403\n",
    "    elif df['OFF_CODE'] == '510':\n",
    "        val = 510\n",
    "    elif df['OFF_CODE'] == '520':\n",
    "        val = 520\n",
    "    elif df['OFF_CODE'] == '64A':\n",
    "        val = 641\n",
    "    elif df['OFF_CODE'] == '64B':\n",
    "        val = 642\n",
    "    elif df['OFF_CODE'] == '720':\n",
    "        val = 720\n",
    "    else:\n",
    "        val=0\n",
    "    return val  \n",
    "df['OFF_CODE'] = df.apply(f_off, axis=1)\n",
    "\n",
    "# Convert population group to easily translated numeric values\n",
    "def f_pop(df):\n",
    "    if df['POP_GROUP'] == '1A':\n",
    "        val = 11\n",
    "    elif df['POP_GROUP'] == '1B':\n",
    "        val = 12\n",
    "    elif df['POP_GROUP'] == '1C':\n",
    "        val = 13\n",
    "    elif df['POP_GROUP'] == '8A':\n",
    "        val = 81\n",
    "    elif df['POP_GROUP'] == '8B':\n",
    "        val = 82\n",
    "    elif df['POP_GROUP'] == '8C':\n",
    "        val = 83\n",
    "    elif df['POP_GROUP'] == '8D':\n",
    "        val = 84\n",
    "    elif df['POP_GROUP'] == '8E':\n",
    "        val = 85\n",
    "    elif df['POP_GROUP'] == '9A':\n",
    "        val = 91\n",
    "    elif df['POP_GROUP'] == '9B':\n",
    "        val = 92\n",
    "    elif df['POP_GROUP'] == '9C':\n",
    "        val = 93\n",
    "    elif df['POP_GROUP'] == '9D':\n",
    "        val = 94\n",
    "    elif df['POP_GROUP'] == '9E':\n",
    "        val = 95\n",
    "    else:\n",
    "        val=df['POP_GROUP']\n",
    "    return val  \n",
    "df['POP_GROUP'] = df.apply(f_pop, axis=1)\n",
    "\n",
    "# Convert victim type\n",
    "def f_vt(df):\n",
    "    if df['VICTIM_TYPE'] == 'I':\n",
    "        val = 1\n",
    "    if df['VICTIM_TYPE'] == 'B':\n",
    "        val = 2\n",
    "    if df['VICTIM_TYPE'] == 'F':\n",
    "        val = 3\n",
    "    if df['VICTIM_TYPE'] == 'G':\n",
    "        val = 4\n",
    "    if df['VICTIM_TYPE'] == 'L':\n",
    "        val = 5\n",
    "    if df['VICTIM_TYPE'] == 'R':\n",
    "        val = 6\n",
    "    if df['VICTIM_TYPE'] == 'S':\n",
    "        val = 7\n",
    "    if df['VICTIM_TYPE'] == 'O':\n",
    "        val = 8\n",
    "    else:\n",
    "        val = 0\n",
    "    return val  \n",
    "df['VICTIM_TYPE'] = df.apply(f_vt, axis=1)\n",
    "\n",
    "# Convert race\n",
    "def f_race(df):\n",
    "    if df['RACE_OF_VICTIM'] == 'W':\n",
    "        val = 1\n",
    "    if df['RACE_OF_VICTIM'] == 'B':\n",
    "        val = 2\n",
    "    if df['RACE_OF_VICTIM'] == 'I':\n",
    "        val = 3\n",
    "    if df['RACE_OF_VICTIM'] == 'A':\n",
    "        val = 4\n",
    "    if df['RACE_OF_VICTIM'] == 'P':\n",
    "        val = 5\n",
    "    else:\n",
    "        val = 0\n",
    "    return val  \n",
    "df['RACE_OF_VICTIM'] = df.apply(f_race, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use offense code as the target variable.  The goal is to be able to predict offense code based on varying features.\n",
    "\n",
    "For the first model, I will select Justifiable Homicide as the target variable.\n",
    "A second model will predict Suspicious Activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of samples in original set1:  1126927\n",
      "No. of samples in training set1:  788848\n",
      "No. of samples in validation set1:  338079\n",
      "No. of features:  21\n"
     ]
    }
   ],
   "source": [
    "# Split data into two sets: Training and Testing.\n",
    "\n",
    "# Split out target variable\n",
    "data_model_y = df.OFF_CODE\n",
    "\n",
    "# Remove target variable from feature list\n",
    "data_model_X = df.drop(['OFF_CODE'], axis=1, inplace = False)\n",
    "\n",
    "# Split the data into training and validation datasets\n",
    "# Save 30% for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_model_X, data_model_y, test_size =0.3, random_state=7)\n",
    "\n",
    "# Check details of the datasets\n",
    "print(\"No. of samples in original set1: \", data_model_X.shape[0])\n",
    "print(\"No. of samples in training set1: \", X_train.shape[0])\n",
    "print(\"No. of samples in validation set1: \", X_val.shape[0])\n",
    "print(\"No. of features: \", X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VICTIM_TYPE</th>\n",
       "      <th>AGE_OF_VICTIM</th>\n",
       "      <th>SEX_OF_VICTIM</th>\n",
       "      <th>RACE_OF_VICTIM</th>\n",
       "      <th>ETHNIC_OF_VIC</th>\n",
       "      <th>VIC_RESIDENT</th>\n",
       "      <th>VIC_INC_MONTH</th>\n",
       "      <th>VIC_INC_DOW</th>\n",
       "      <th>NUM_STATE_CODE</th>\n",
       "      <th>POP_GROUP</th>\n",
       "      <th>...</th>\n",
       "      <th>CTRY_REGION</th>\n",
       "      <th>AGENCY_IND</th>\n",
       "      <th>CURRENT_POP1</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>density</th>\n",
       "      <th>military</th>\n",
       "      <th>incorporated</th>\n",
       "      <th>timezone</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43974.0</td>\n",
       "      <td>41.6722</td>\n",
       "      <td>-70.3599</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43974.0</td>\n",
       "      <td>41.6722</td>\n",
       "      <td>-70.3599</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43974.0</td>\n",
       "      <td>41.6722</td>\n",
       "      <td>-70.3599</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43974.0</td>\n",
       "      <td>41.6722</td>\n",
       "      <td>-70.3599</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43974.0</td>\n",
       "      <td>41.6722</td>\n",
       "      <td>-70.3599</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945578</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>86005.0</td>\n",
       "      <td>48.7543</td>\n",
       "      <td>-122.4687</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945579</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>86005.0</td>\n",
       "      <td>48.7543</td>\n",
       "      <td>-122.4687</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945583</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13338.0</td>\n",
       "      <td>48.8525</td>\n",
       "      <td>-122.5893</td>\n",
       "      <td>775.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945584</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13338.0</td>\n",
       "      <td>48.8525</td>\n",
       "      <td>-122.5893</td>\n",
       "      <td>775.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945593</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>94111.0</td>\n",
       "      <td>46.5923</td>\n",
       "      <td>-120.5496</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1126927 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VICTIM_TYPE  AGE_OF_VICTIM  SEX_OF_VICTIM  RACE_OF_VICTIM  \\\n",
       "0                  0             27              1               0   \n",
       "1                  0             25              1               0   \n",
       "2                  0             51              2               0   \n",
       "4                  0             50              2               0   \n",
       "21                 0             30              1               0   \n",
       "...              ...            ...            ...             ...   \n",
       "3945578            0             31              1               0   \n",
       "3945579            0             23              2               0   \n",
       "3945583            0             58              2               0   \n",
       "3945584            0             59              1               0   \n",
       "3945593            0             51              1               0   \n",
       "\n",
       "         ETHNIC_OF_VIC  VIC_RESIDENT  VIC_INC_MONTH  VIC_INC_DOW  \\\n",
       "0                    0             1              1            6   \n",
       "1                    1             2              1            6   \n",
       "2                    1             2              1            6   \n",
       "4                    0             1              1            7   \n",
       "21                   2             2              1            6   \n",
       "...                ...           ...            ...          ...   \n",
       "3945578              1             2             12            2   \n",
       "3945579              1             2             11            4   \n",
       "3945583              1             2              5            5   \n",
       "3945584              1             2              5            5   \n",
       "3945593              2             2             10            4   \n",
       "\n",
       "         NUM_STATE_CODE  POP_GROUP  ...  CTRY_REGION  AGENCY_IND  \\\n",
       "0                    20        4.0  ...            1           1   \n",
       "1                    20        4.0  ...            1           1   \n",
       "2                    20        4.0  ...            1           1   \n",
       "4                    20        4.0  ...            1           1   \n",
       "21                   20        4.0  ...            1           1   \n",
       "...                 ...        ...  ...          ...         ...   \n",
       "3945578              46        3.0  ...            4           1   \n",
       "3945579              46        3.0  ...            4           1   \n",
       "3945583              46        5.0  ...            4           1   \n",
       "3945584              46        5.0  ...            4           1   \n",
       "3945593              46        3.0  ...            4           1   \n",
       "\n",
       "         CURRENT_POP1      lat       lng  density  military  incorporated  \\\n",
       "0             43974.0  41.6722  -70.3599    284.0         0             1   \n",
       "1             43974.0  41.6722  -70.3599    284.0         0             1   \n",
       "2             43974.0  41.6722  -70.3599    284.0         0             1   \n",
       "4             43974.0  41.6722  -70.3599    284.0         0             1   \n",
       "21            43974.0  41.6722  -70.3599    284.0         0             1   \n",
       "...               ...      ...       ...      ...       ...           ...   \n",
       "3945578       86005.0  48.7543 -122.4687   1241.0         0             1   \n",
       "3945579       86005.0  48.7543 -122.4687   1241.0         0             1   \n",
       "3945583       13338.0  48.8525 -122.5893    775.0         0             1   \n",
       "3945584       13338.0  48.8525 -122.5893    775.0         0             1   \n",
       "3945593       94111.0  46.5923 -120.5496   1302.0         0             1   \n",
       "\n",
       "         timezone  ranking  \n",
       "0               1      2.0  \n",
       "1               1      2.0  \n",
       "2               1      2.0  \n",
       "4               1      2.0  \n",
       "21              1      2.0  \n",
       "...           ...      ...  \n",
       "3945578         4      2.0  \n",
       "3945579         4      2.0  \n",
       "3945583         4      3.0  \n",
       "3945584         4      3.0  \n",
       "3945593         4      2.0  \n",
       "\n",
       "[1126927 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_model_y\n",
    "data_model_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 788848 entries, 1816890 to 2238547\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   VICTIM_TYPE     788848 non-null  int64  \n",
      " 1   AGE_OF_VICTIM   788848 non-null  int64  \n",
      " 2   SEX_OF_VICTIM   788848 non-null  int64  \n",
      " 3   RACE_OF_VICTIM  788848 non-null  int64  \n",
      " 4   ETHNIC_OF_VIC   788848 non-null  int64  \n",
      " 5   VIC_RESIDENT    788848 non-null  int64  \n",
      " 6   VIC_INC_MONTH   788848 non-null  int64  \n",
      " 7   VIC_INC_DOW     788848 non-null  int64  \n",
      " 8   NUM_STATE_CODE  788848 non-null  int64  \n",
      " 9   POP_GROUP       788848 non-null  float64\n",
      " 10  CTRY_DIVISION   788848 non-null  int64  \n",
      " 11  CTRY_REGION     788848 non-null  int64  \n",
      " 12  AGENCY_IND      788848 non-null  int64  \n",
      " 13  CURRENT_POP1    788848 non-null  float64\n",
      " 14  lat             788848 non-null  float64\n",
      " 15  lng             788848 non-null  float64\n",
      " 16  density         788848 non-null  float64\n",
      " 17  military        788848 non-null  int64  \n",
      " 18  incorporated    788848 non-null  int64  \n",
      " 19  timezone        788848 non-null  int64  \n",
      " 20  ranking         788848 non-null  float64\n",
      "dtypes: float64(6), int64(15)\n",
      "memory usage: 132.4 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create decision tree classifer object\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#decisiontree = DecisionTreeClassifier(random_state=0, class_weight=\"balanced\")\n",
    "decisiontree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Train model\n",
    "tree = decisiontree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values\n",
    "y_pred_tree = tree.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          91       0.16      0.21      0.18       262\n",
      "          92       0.09      0.09      0.09        11\n",
      "          93       0.08      0.10      0.09        10\n",
      "         100       0.19      0.29      0.23      1322\n",
      "         111       0.13      0.14      0.13      1843\n",
      "         112       0.41      0.42      0.41       505\n",
      "         113       0.14      0.15      0.15       133\n",
      "         114       0.40      0.37      0.38      2104\n",
      "         120       0.41      0.50      0.45      7490\n",
      "         131       0.41      0.51      0.45     23283\n",
      "         132       0.45      0.48      0.46     59003\n",
      "         133       0.39      0.41      0.40     18873\n",
      "         200       0.44      0.54      0.48       965\n",
      "         210       0.10      0.10      0.10       153\n",
      "         220       0.37      0.40      0.38     32217\n",
      "         231       0.13      0.12      0.12       433\n",
      "         232       0.11      0.10      0.10       372\n",
      "         233       0.19      0.20      0.19       838\n",
      "         234       0.24      0.22      0.23     13036\n",
      "         235       0.17      0.23      0.19        43\n",
      "         236       0.46      0.48      0.47     37920\n",
      "         237       0.10      0.09      0.09      3776\n",
      "         238       0.39      0.36      0.37     37307\n",
      "         240       0.17      0.15      0.16     11164\n",
      "         250       0.32      0.34      0.33      4031\n",
      "         261       0.29      0.28      0.29      6937\n",
      "         262       0.34      0.32      0.33      6765\n",
      "         263       0.38      0.35      0.36      5825\n",
      "         264       0.11      0.17      0.14        23\n",
      "         265       0.13      0.12      0.12       355\n",
      "         266       0.29      0.25      0.27      2840\n",
      "         267       0.33      0.21      0.26        28\n",
      "         270       0.75      0.73      0.74       742\n",
      "         280       0.50      0.52      0.51      7260\n",
      "         290       0.34      0.30      0.32     44837\n",
      "         351       0.00      0.00      0.00      2127\n",
      "         352       0.00      0.00      0.00       988\n",
      "         361       0.16      0.23      0.19        26\n",
      "         362       0.25      0.21      0.23       236\n",
      "         370       0.00      0.00      0.00        62\n",
      "         393       0.00      0.00      0.00         3\n",
      "         401       0.00      0.00      0.00        17\n",
      "         402       0.00      0.00      0.00         6\n",
      "         403       0.00      0.00      0.00         1\n",
      "         510       0.00      0.00      0.00         7\n",
      "         520       0.01      0.00      0.00      1863\n",
      "         641       0.56      0.82      0.67        33\n",
      "         642       0.00      0.00      0.00         0\n",
      "         720       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.38    338079\n",
      "   macro avg       0.22      0.23      0.23    338079\n",
      "weighted avg       0.37      0.38      0.38    338079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create classification report\n",
    "print(classification_report(y_val, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   54     0     0     4     3     0     0     0    19    52    26     4\n",
      "      6     0    16     0     0     0     5     0    22     1     9     7\n",
      "      0     2     3     4     0     0     1     0     0     3    17     1\n",
      "      0     0     0     0     0     0     0     0     0     3     0     0\n",
      "      0]\n",
      " [    0     1     0     0     0     0     0     0     1     1     5     0\n",
      "      0     0     0     0     0     0     0     0     1     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     2\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0     0     1     0     0     0     0     0     0     2     1     0\n",
      "      0     0     1     0     0     0     0     0     3     0     0     1\n",
      "      0     0     1     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    2     0     0   387    49     3     3    23   135   183   231    55\n",
      "      3     0    79     1     1     2    15     0    19     1    43    14\n",
      "      0     3     4     2     0     1     3     0     0     7    38     6\n",
      "      0     0     0     1     0     0     1     0     0     6     1     0\n",
      "      0]\n",
      " [    2     0     0    60   250    33     7    95    42   115   438   136\n",
      "      0     0   109     6     2     4    51     0   108     9   155    34\n",
      "      8    12    15    14     0     1     2     0     0    10   104     1\n",
      "      1     2     8     4     0     1     1     0     0     2     1     0\n",
      "      0]\n",
      " [    0     0     0     5    33   214     3    23     6    21    88    16\n",
      "      4     1    16     0     0     0    10     0    13     1    22     3\n",
      "      2     2     2     2     0     0     2     0     0     0    11     1\n",
      "      1     1     1     0     0     1     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0     0     0     4    12     3    20     9     2    11    26     4\n",
      "      3     0     5     0     0     0     5     0     9     1     6     2\n",
      "      1     2     0     0     0     0     1     0     0     0     4     0\n",
      "      0     1     1     0     0     0     0     0     0     1     0     0\n",
      "      0]\n",
      " [    1     0     0    27    95    24     8   777    23   152   440   124\n",
      "      6     3    86     1     2     1    40     0    59     1    83    23\n",
      "      5     6    16     3     0     1     1     0     1     8    50     3\n",
      "      1     7    21     3     0     0     1     0     0     1     0     0\n",
      "      0]\n",
      " [   10     1     1   178    25     9     3    22  3721   430   707   172\n",
      "     11     5   479     3     6    15   118     1   344    41   309   184\n",
      "     31    63    50    39     0     5    22     0     2    39   353    30\n",
      "      6     0     1     0     0     1     0     0     0    53     0     0\n",
      "      0]\n",
      " [   61     0     1   234    97    16     4    86   448 11779  3162   704\n",
      "     49    12  1204    17     3    33   374     0   835   124   891   368\n",
      "     54   154   121   111     1     7    36     0     3   125  1786   120\n",
      "     25     1    11     1     2     0     0     0     0   222     0     1\n",
      "      0]\n",
      " [   43     1     4   385   446   105    38   395   981  4077 28172  2806\n",
      "    109    15  3342    67    55   198  1589     9  3180   410  3669  1251\n",
      "    205   598   533   401     4    48   203     1    18   219  4925   260\n",
      "     78     8    47     8     0     2     0     0     0    90     6     1\n",
      "      1]\n",
      " [   10     0     1   125   129    21     6    94   252   953  3117  7660\n",
      "     29    11  1088    16    22    49   514     1   875   124  1153   341\n",
      "     67   217   161   135     3     9    72     1     5   100  1353    62\n",
      "     27     2    22     9     0     0     0     0     0    35     1     1\n",
      "      0]\n",
      " [    1     0     0     3     6     1     0     4     7    43    92    22\n",
      "    517     1    38     0     2     0    19     0    54     3    35    13\n",
      "      5    11     3     5     0     0     3     0     2    10    63     2\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    1     0     0     3     0     0     0     1     2    10    23    15\n",
      "      0    16    13     0     0     0     5     0     8     3    18     3\n",
      "      2     2     1     3     0     0     3     0     0     1    14     2\n",
      "      0     0     1     3     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [   20     1     0   155    87    15     8    66   536  1578  3465  1028\n",
      "     89     7 12801    20    29    31  1205     6  1798   236  2309   828\n",
      "    127   396   292   231     3    28   124     4    17   264  4298    58\n",
      "     18     1     3     0     0     1     0     0     0    34     0     0\n",
      "      0]\n",
      " [    0     0     0     3     3     1     1     2     8    33    77    26\n",
      "      0     1    47    51     1     4    12     0    26     4    38    12\n",
      "      2    13     9     6     0     1     3     0     1     6    39     0\n",
      "      0     0     1     0     0     2     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0     0     0     2     6     1     0     3     4    16    62    21\n",
      "      0     0    24     3    38     2    20     0    36     3    48    14\n",
      "      6     7    11     5     0     0     1     0     0     5    32     1\n",
      "      0     0     1     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0     0     0     2     0     0     0     0    21    76   235    48\n",
      "      2     0    21     1     0   166    15     0    29     3    54    10\n",
      "      5    14     6    35     0     0     5     0     0    34    48     6\n",
      "      1     0     0     0     0     0     0     0     0     1     0     0\n",
      "      0]\n",
      " [   10     1     0    36    61     4     6    56   214   618  1981   595\n",
      "     35     7  1589    24    22    21  2853     2   933   153   904   368\n",
      "    154   308   337   143     3     9    67     0    12   122  1311    41\n",
      "     10     0     6     1     0     0     0     0     0    17     2     0\n",
      "      0]\n",
      " [    0     0     0     0     0     0     0     0     1     2     2     3\n",
      "      1     0     3     0     0     2     3    10     3     0     3     1\n",
      "      0     3     2     0     0     0     0     0     0     0     4     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [   18     2     1    64   127     7     4    43   458  1130  3443  1077\n",
      "     56    16  2191    36    26    48   907     0 18046   437  2616  1028\n",
      "    187   414   515   262     2    38   138     1    17   372  4089    60\n",
      "     13     2     3     0     1     0     0     0     0    25     0     0\n",
      "      0]\n",
      " [    3     0     0     5    15     1     0     6    65   239   559   156\n",
      "     12     5   324     8     4     8   172     0   534   322   325   220\n",
      "     35    77    67    52     0     1    43     0     3    54   450     8\n",
      "      1     0     0     0     0     0     0     0     0     2     0     0\n",
      "      0]\n",
      " [   19     0     1    91   152    19     7    88   498  1419  4520  1400\n",
      "     62    12  3158    49    43    46  1016     7  3252   354 13276  1134\n",
      "    482   641   689   532     8    40   194     2    30   611  3325    65\n",
      "     20     2     3     0     0     1     0     0     0    36     3     0\n",
      "      0]\n",
      " [   16     2     1    47    44    11     3    19   218   615  1608   396\n",
      "     26    11  1265    12    14    29   399     2  1389   209  1166  1627\n",
      "     97   180   149   125     1     9    50     0     4   176  1174    43\n",
      "     12     0     0     0     0     0     0     0     0    13     2     0\n",
      "      0]\n",
      " [    3     0     0     3     3     2     0     5    32    65   204    76\n",
      "      2     1   165     3     4    12   161     0   179    23   487    63\n",
      "   1376   389    96    90     0     6   119     0    16   277   140    19\n",
      "      7     0     0     0     0     0     0     0     0     3     0     0\n",
      "      0]\n",
      " [    4     1     0     8    17     2     3    14    92   268   722   244\n",
      "     11    10   467     7    11    24   300     2   482    80   644   166\n",
      "    358  1954   137   140     1    11   146     1    11   103   448    30\n",
      "      7     0     0     1     0     0     0     0     0    10     0     0\n",
      "      0]\n",
      " [    5     0     0     8    15     4     0     9    74   216   625   215\n",
      "      4     3   408    16    12     8   370     2   597    59   702   146\n",
      "    108   166  2181   142     1     8   123     2     7   123   388     7\n",
      "      2     0     1     0     0     0     0     0     0     8     0     0\n",
      "      0]\n",
      " [    3     0     0    12    14     1     3     8    57   179   520   158\n",
      "      7     3   342    10     4    43   174     2   390    47   522   130\n",
      "    136   174   210  2011     2    10    42     0    12   137   368    60\n",
      "     21     0     5     0     0     0     0     0     0     8     0     0\n",
      "      0]\n",
      " [    0     0     0     0     0     0     0     0     0     1     0     2\n",
      "      0     0     0     0     0     0     1     0     1     0     0     1\n",
      "      0     6     0     0     4     0     0     0     0     3     3     1\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0     0     0     0     1     0     0     0     7    17    49    22\n",
      "      1     0    26     0     0     0    16     0    38     8    43     3\n",
      "      6    15    13    16     0    42     8     0     0     4    20     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    3     0     0     2     8     2     0     2    25    69   272    77\n",
      "      7     2   166     3     3     5    79     0   180    22   227    69\n",
      "    263   134   170    56     0    18   712     0     3    84   171     3\n",
      "      0     0     0     0     0     0     0     0     0     2     1     0\n",
      "      0]\n",
      " [    0     0     0     0     0     0     0     0     0     2     2     2\n",
      "      0     0     0     0     0     0     0     0     5     1     5     0\n",
      "      0     0     1     1     0     0     0     6     0     0     3     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0     0     0     1     0     0     0     0     2     4    18     6\n",
      "      0     0    16     0     0     0     9     0    13     4    23     4\n",
      "     42    17     5    18     0     1     1     0   540     3    14     1\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    3     0     0    10    12     2     1     2    70   147   240    88\n",
      "      6     0   308     3     6    53   117     0   483    40   482   161\n",
      "    298    89   112   172     0     1   110     0     2  3765   164   198\n",
      "     50     1     0     0     0     0     0     0     0    64     0     0\n",
      "      0]\n",
      " [   29     0     1   135   117    18     7    84   682  2907  6837  1814\n",
      "     99    16  4894    47    41    59  1253    16  5270   465  3449  1110\n",
      "    232   515   433   326     0    29   174     0    17   279 13292    61\n",
      "     23     2     3     0     0     1     0     0     0   100     0     0\n",
      "      0]\n",
      " [    2     1     0    15    11     2     0     5    65   273   453   123\n",
      "      3     0   123     1     3    18    43     0   121    12   150    50\n",
      "     29    53    17    75     2     1    12     0     0   272   107     4\n",
      "     53     0     1     0     0     1     0     0     0    26     0     0\n",
      "      0]\n",
      " [    1     0     0     6     3     0     0     0    22    98   189    77\n",
      "      3     0    51     0     0     6    22     0    45     8    66    26\n",
      "     27    28     1    51     0     0     3     0     0   151    28    67\n",
      "      0     0     0     0     0     0     0     0     0     9     0     0\n",
      "      0]\n",
      " [    0     0     0     0     1     1     1     0     0     2     5     1\n",
      "      0     0     1     0     0     0     0     0     1     0     1     0\n",
      "      0     0     0     0     0     0     0     0     0     0     1     0\n",
      "      0     6     3     1     0     0     0     0     0     0     1     0\n",
      "      0]\n",
      " [    0     0     0     0    17     3     1    15     2    25    55    21\n",
      "      0     0     4     0     0     0     5     0     5     0    20     0\n",
      "      0     2     1     1     0     0     0     0     0     0     3     0\n",
      "      1     1    49     3     0     0     1     0     0     0     1     0\n",
      "      0]\n",
      " [    0     0     0     1     8     1     1     2     0     4    11    16\n",
      "      0     4     0     0     0     0     0     0     1     0     4     0\n",
      "      0     1     0     0     0     0     0     0     0     1     1     0\n",
      "      0     1     5     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0     0     0     0     0     0     0     0     0     1     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     2     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0     0     0     1     2     0     0     0     4     1     4     0\n",
      "      0     0     0     0     0     0     0     0     1     0     0     0\n",
      "      1     0     0     0     0     0     0     0     0     1     0     0\n",
      "      0     0     1     0     0     0     0     0     0     1     0     0\n",
      "      0]\n",
      " [    0     0     0     0     1     0     0     2     0     1     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     2     0\n",
      "      0]\n",
      " [    0     0     0     1     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0     0     0     0     0     0     0     0     2     2     1     0\n",
      "      0     0     0     0     0     1     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     1     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    8     0     0    36     6     1     0     4   184   732   187    81\n",
      "      5     0    94     0     3     2    11     0    57     5    52    22\n",
      "      7    11     4    22     0     0     1     0     0   125   170    24\n",
      "      4     0     1     0     0     0     0     0     0     4     0     0\n",
      "      0]\n",
      " [    0     0     0     0     0     1     0     1     0     0     1     0\n",
      "      0     0     0     0     0     0     0     0     2     0     1     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0    27     0\n",
      "      0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     2     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     2     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]]\n"
     ]
    }
   ],
   "source": [
    "# Use Confusion Matrix to evaluate the model \n",
    "from sklearn.metrics import confusion_matrix\n",
    "tree_cm = confusion_matrix(y_val, y_pred_tree)\n",
    "\n",
    "# Output confusion matrix array\n",
    "# Note that print options need to be modified to accomodate large array\n",
    "with np.printoptions(threshold=np.inf):\n",
    "    print(tree_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Keras Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import metrics\n",
    "import keras.backend as K\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create standardizer\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# Standardize features\n",
    "feat_std = standardizer.fit_transform(X_train)\n",
    "\n",
    "# This function returns a compiled neural network\n",
    "\n",
    "num_features = feat_std.shape[1]\n",
    "\n",
    "def build_network():\n",
    "\n",
    "    # Define the keras model\n",
    "    nn = Sequential()\n",
    "    nn.add(Dense(400, activation='relu', input_dim=num_features))\n",
    "    nn.add(Dense(400, activation='relu'))\n",
    "    nn.add(Dense(400, activation='relu'))\n",
    "    nn.add(Dense(400, activation='relu'))\n",
    "    nn.add(Dense(400, activation='relu'))\n",
    "    \n",
    "    # Use number of output classes in output layer\n",
    "    nn.add(Dense(49, activation='softmax'))\n",
    "\n",
    "    # Compile the keras model\n",
    "    nn.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "  \n",
    "    return nn\n",
    "\n",
    "# Compile Keras neural network\n",
    "clf = KerasClassifier(build_fn=build_network, epochs=7, batch_size=1000, verbose=0)\n",
    "\n",
    "# Fit the keras model on the dataset\n",
    "history = clf.fit(feat_std,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values\n",
    "val_std = standardizer.fit_transform(X_val)\n",
    "y_pred_nn = clf.predict(val_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          91       0.00      0.00      0.00       262\n",
      "          92       0.00      0.00      0.00        11\n",
      "          93       0.00      0.00      0.00        10\n",
      "         100       0.53      0.05      0.10      1322\n",
      "         111       0.37      0.01      0.03      1843\n",
      "         112       0.84      0.23      0.36       505\n",
      "         113       0.00      0.00      0.00       133\n",
      "         114       0.36      0.22      0.27      2104\n",
      "         120       0.35      0.06      0.11      7490\n",
      "         131       0.32      0.20      0.24     23283\n",
      "         132       0.27      0.70      0.39     59003\n",
      "         133       0.37      0.19      0.25     18873\n",
      "         200       0.59      0.24      0.34       965\n",
      "         210       0.00      0.00      0.00       153\n",
      "         220       0.23      0.16      0.19     32217\n",
      "         231       0.32      0.03      0.05       433\n",
      "         232       0.00      0.00      0.00       372\n",
      "         233       0.40      0.09      0.15       838\n",
      "         234       0.34      0.06      0.10     13036\n",
      "         235       0.00      0.00      0.00        43\n",
      "         236       0.39      0.36      0.37     37920\n",
      "         237       0.20      0.01      0.02      3776\n",
      "         238       0.36      0.32      0.34     37307\n",
      "         240       0.22      0.03      0.05     11164\n",
      "         250       0.54      0.15      0.23      4031\n",
      "         261       0.35      0.15      0.21      6937\n",
      "         262       0.54      0.16      0.25      6765\n",
      "         263       0.57      0.23      0.33      5825\n",
      "         264       0.00      0.00      0.00        23\n",
      "         265       0.00      0.00      0.00       355\n",
      "         266       0.26      0.33      0.29      2840\n",
      "         267       0.00      0.00      0.00        28\n",
      "         270       0.88      0.61      0.72       742\n",
      "         280       0.60      0.41      0.48      7260\n",
      "         290       0.27      0.27      0.27     44837\n",
      "         351       0.05      0.00      0.00      2127\n",
      "         352       0.00      0.00      0.00       988\n",
      "         361       0.00      0.00      0.00        26\n",
      "         362       0.44      0.05      0.08       236\n",
      "         370       0.00      0.00      0.00        62\n",
      "         393       0.00      0.00      0.00         3\n",
      "         401       0.00      0.00      0.00        17\n",
      "         402       0.00      0.00      0.00         6\n",
      "         403       0.00      0.00      0.00         1\n",
      "         510       0.00      0.00      0.00         7\n",
      "         520       0.07      0.00      0.00      1863\n",
      "         641       0.86      0.73      0.79        33\n",
      "         720       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.31    338079\n",
      "   macro avg       0.25      0.13      0.15    338079\n",
      "weighted avg       0.32      0.31      0.28    338079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create classification report\n",
    "print(classification_report(y_val, y_pred_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Random Forest Classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random forest classifer object\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomforest = RandomForestClassifier(random_state=0, n_estimators=100, n_jobs=-1, max_depth=25, bootstrap=False)\n",
    "#randomforest = RandomForestClassifier(random_state=0, n_estimators=5, n_jobs=-1, max_depth=25, bootstrap=False)\n",
    "\n",
    "# Train model\n",
    "forest = randomforest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values\n",
    "y_pred_forest = forest.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          91       0.23      0.16      0.19       262\n",
      "          92       0.17      0.09      0.12        11\n",
      "          93       0.09      0.10      0.10        10\n",
      "         100       0.30      0.23      0.26      1322\n",
      "         111       0.24      0.13      0.17      1843\n",
      "         112       0.62      0.42      0.50       505\n",
      "         113       0.29      0.14      0.18       133\n",
      "         114       0.54      0.36      0.43      2104\n",
      "         120       0.51      0.45      0.48      7490\n",
      "         131       0.48      0.47      0.47     23283\n",
      "         132       0.42      0.57      0.48     59003\n",
      "         133       0.45      0.41      0.43     18873\n",
      "         200       0.64      0.50      0.56       965\n",
      "         210       0.14      0.08      0.10       153\n",
      "         220       0.39      0.39      0.39     32217\n",
      "         231       0.22      0.11      0.15       433\n",
      "         232       0.20      0.11      0.15       372\n",
      "         233       0.25      0.18      0.21       838\n",
      "         234       0.28      0.21      0.24     13036\n",
      "         235       0.26      0.23      0.24        43\n",
      "         236       0.48      0.48      0.48     37920\n",
      "         237       0.16      0.08      0.11      3776\n",
      "         238       0.40      0.38      0.39     37307\n",
      "         240       0.20      0.15      0.17     11164\n",
      "         250       0.38      0.32      0.35      4031\n",
      "         261       0.34      0.28      0.31      6937\n",
      "         262       0.41      0.32      0.36      6765\n",
      "         263       0.45      0.35      0.39      5825\n",
      "         264       0.14      0.13      0.13        23\n",
      "         265       0.21      0.10      0.14       355\n",
      "         266       0.32      0.28      0.30      2840\n",
      "         267       0.33      0.21      0.26        28\n",
      "         270       0.82      0.73      0.77       742\n",
      "         280       0.55      0.53      0.54      7260\n",
      "         290       0.32      0.34      0.33     44837\n",
      "         351       0.01      0.00      0.00      2127\n",
      "         352       0.00      0.00      0.00       988\n",
      "         361       0.30      0.23      0.26        26\n",
      "         362       0.36      0.25      0.29       236\n",
      "         370       0.00      0.00      0.00        62\n",
      "         393       0.00      0.00      0.00         3\n",
      "         401       0.00      0.00      0.00        17\n",
      "         402       0.00      0.00      0.00         6\n",
      "         403       0.00      0.00      0.00         1\n",
      "         510       0.00      0.00      0.00         7\n",
      "         520       0.01      0.00      0.00      1863\n",
      "         641       0.84      0.82      0.83        33\n",
      "         642       0.00      0.00      0.00         0\n",
      "         720       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.40    338079\n",
      "   macro avg       0.28      0.23      0.25    338079\n",
      "weighted avg       0.39      0.40      0.39    338079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create classification report\n",
    "print(classification_report(y_val, y_pred_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.396 (0.001)\n"
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/bagging-ensemble-with-python/\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# define the model\n",
    "model = BaggingClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, data_model_X, data_model_y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.737743430882"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://towardsdatascience.com/machine-learning-part-18-boosting-algorithms-gradient-boosting-in-python-ef5ae6965be4\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "regressor = GradientBoostingRegressor(\n",
    "    max_depth=10,    #leaves\n",
    "    n_estimators=10,    #trees\n",
    "    learning_rate=1.0    # scales the contribution of each tree. If you set it to a low value, you will need more trees in the ensemble to fit the training set, but the overall variance will be lower.\n",
    ")\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "errors = [mean_squared_error(y_val, y_pred) for y_pred in regressor.staged_predict(X_val)]\n",
    "best_n_estimators = np.argmin(errors)\n",
    "\n",
    "best_regressor = GradientBoostingRegressor(\n",
    "    max_depth=2,\n",
    "    n_estimators=best_n_estimators,\n",
    "    learning_rate=1.0\n",
    ")\n",
    "best_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred_boost = best_regressor.predict(X_val)\n",
    "mean_absolute_error(y_val, y_pred_boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Boosting model resulted in better accuracy than the other Python models, resulting in 50% accuracy.  \n",
    "As expected, it performed better than the bagging ensemble model, which performed better than the random forest ensemble.  After adjusting hyperparameters for random forests, I was able to improve accuracy to 40%.\n",
    "\n",
    "I increased the neural network accuracy by adjusting hyperparameters and adding hidden layers, up to 31%.  \n",
    "\n",
    "Unexpectedly, the decision tree model provided better accuracy than the random forest ensemble model.\n",
    "After adjusting hyperparameters for decision trees and random forests, I was able to improve to 28%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find most important features in Random Forest model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate feature importances\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Rearrange feature names so they match the sorted feature importances\n",
    "names = [X_train.columns[i] for i in indices]\n",
    "\n",
    "# Create plot\n",
    "plt.figure()\n",
    "\n",
    "# Create plot title\n",
    "plt.title(\"Feature Importance\")\n",
    "\n",
    "# Add bars\n",
    "plt.bar(range(X_train.shape[1]), importances[indices])\n",
    "\n",
    "# Add feature names as x-axis labels\n",
    "plt.xticks(range(X_train.shape[1]), names, rotation=90)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run random forest, limiting to important features \n",
    "\n",
    "# Drop features w/ little importance\n",
    "data_model_X.drop(['RACE_OF_VICTIM', 'AGENCY_IND', 'military', 'incorporated', 'VICTIM_TYPE'],\n",
    "                  axis=1, inplace = True)\n",
    "\n",
    "# Split the data into training and validation datasets\n",
    "# Save 30% for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_model_X, data_model_y, test_size =0.3, random_state=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          91       0.16      0.21      0.18       262\n",
      "          92       0.09      0.09      0.09        11\n",
      "          93       0.08      0.10      0.09        10\n",
      "         100       0.19      0.29      0.23      1322\n",
      "         111       0.13      0.14      0.13      1843\n",
      "         112       0.41      0.42      0.41       505\n",
      "         113       0.14      0.15      0.15       133\n",
      "         114       0.40      0.37      0.38      2104\n",
      "         120       0.41      0.50      0.45      7490\n",
      "         131       0.41      0.51      0.45     23283\n",
      "         132       0.45      0.48      0.46     59003\n",
      "         133       0.39      0.41      0.40     18873\n",
      "         200       0.44      0.54      0.48       965\n",
      "         210       0.10      0.10      0.10       153\n",
      "         220       0.37      0.40      0.38     32217\n",
      "         231       0.13      0.12      0.12       433\n",
      "         232       0.11      0.10      0.10       372\n",
      "         233       0.19      0.20      0.19       838\n",
      "         234       0.24      0.22      0.23     13036\n",
      "         235       0.17      0.23      0.19        43\n",
      "         236       0.46      0.48      0.47     37920\n",
      "         237       0.10      0.09      0.09      3776\n",
      "         238       0.39      0.36      0.37     37307\n",
      "         240       0.17      0.15      0.16     11164\n",
      "         250       0.32      0.34      0.33      4031\n",
      "         261       0.29      0.28      0.29      6937\n",
      "         262       0.34      0.32      0.33      6765\n",
      "         263       0.38      0.35      0.36      5825\n",
      "         264       0.11      0.17      0.14        23\n",
      "         265       0.13      0.12      0.12       355\n",
      "         266       0.29      0.25      0.27      2840\n",
      "         267       0.33      0.21      0.26        28\n",
      "         270       0.75      0.73      0.74       742\n",
      "         280       0.50      0.52      0.51      7260\n",
      "         290       0.34      0.30      0.32     44837\n",
      "         351       0.00      0.00      0.00      2127\n",
      "         352       0.00      0.00      0.00       988\n",
      "         361       0.16      0.23      0.19        26\n",
      "         362       0.25      0.21      0.23       236\n",
      "         370       0.00      0.00      0.00        62\n",
      "         393       0.00      0.00      0.00         3\n",
      "         401       0.00      0.00      0.00        17\n",
      "         402       0.00      0.00      0.00         6\n",
      "         403       0.00      0.00      0.00         1\n",
      "         510       0.00      0.00      0.00         7\n",
      "         520       0.01      0.00      0.00      1863\n",
      "         641       0.56      0.82      0.67        33\n",
      "         642       0.00      0.00      0.00         0\n",
      "         720       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.38    338079\n",
      "   macro avg       0.22      0.23      0.23    338079\n",
      "weighted avg       0.37      0.38      0.38    338079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rerun random forest classifer object\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomforest = RandomForestClassifier(random_state=0, n_estimators=100, n_jobs=-1, max_depth=25, bootstrap=False)\n",
    "#randomforest = RandomForestClassifier(random_state=0, n_estimators=284, n_jobs=-1, max_depth=17, bootstrap=False)\n",
    "\n",
    "# Train model\n",
    "forest = randomforest.fit(X_train, y_train)\n",
    "\n",
    "# Predict values\n",
    "y_pred_forest = forest.predict(X_val)\n",
    "\n",
    "# Create classification report\n",
    "print(classification_report(y_val, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Information\n",
    "\n",
    "Name: Amie Davis\n",
    "\n",
    "Course: DSC630 - Predictive Analytics\n",
    "\n",
    "Assignment Number: Final Project Part 4\n",
    "\n",
    "Purpose: Build model(s) for each state\n",
    "\n",
    "Usage: Python 3.7.6\n",
    "\n",
    "   Developed using Jupter Notebook 6.0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source\n",
    "Uniform Crime Reporting Program Data: National Incident-Based Reporting System, [United States], 2016; United States Federal Bureau of Investigation; Inter-university Consortium for Political and Social Research (ICPSR), University of Michigan; https://www.icpsr.umich.edu/icpsrweb/NACJD/NIBRS/ \n",
    "\n",
    "\n",
    "Geodetic Data for US Cities: https://simplemaps.com/data/us-cities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5\n",
    "\n",
    "In Part 5, I will build separate models for the top 6 reporting states to predict the type of offenses committed, given location information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress Warnings\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore') \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (7,11,14,15,16,17,18,19,41,42,44,46,51,52,53,54,56) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load data into dataframe\n",
    "data_file = \"Data\\crime_offenses_top6.csv\"    # Data from Top 6 States\n",
    "df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'X1', 'ORI', 'INC_NUM', 'VIC_INC_DATE', 'VICTIM_TYPE',\n",
      "       'ACT_TYPE_OFFC', 'ASSG_TYPE_OFFC', 'AGE_OF_VICTIM', 'SEX_OF_VICTIM',\n",
      "       'RACE_OF_VICTIM', 'ETHNIC_OF_VIC', 'VIC_RESIDENT', 'ASSAULT_CIRC1',\n",
      "       'ASSAULT_CIRC2', 'JUST_HOM_CIRC', 'INJURY_TYPE1', 'INJURY_TYPE2',\n",
      "       'INJURY_TYPE3', 'INJURY_TYPE4', 'INJURY_TYPE5', 'NUM_RECS_PER_VICTIM',\n",
      "       'VIC_INC_YEAR', 'VIC_INC_MONTH', 'VIC_INC_DAY', 'VIC_INC_DOW',\n",
      "       'NUM_STATE_CODE', 'CITY', 'STATE', 'POP_GROUP', 'CTRY_DIVISION',\n",
      "       'CTRY_REGION', 'AGENCY_IND', 'CORE_CITY', 'FBI_OFFICE', 'JUDICIAL_DIST',\n",
      "       'CURRENT_POP1', 'UCR_COUNTY_CD1', 'MSA_CD1', 'LAST_POP1',\n",
      "       'FIPS_COUNTY1', 'city_ascii', 'state_name', 'county_fips',\n",
      "       'county_name', 'county_fips_all', 'county_name_all', 'lat', 'lng',\n",
      "       'population', 'density', 'source', 'military', 'incorporated',\n",
      "       'timezone', 'ranking', 'zips', 'id', 'OFF_CODE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ACT_TYPE_OFFC', 'ASSG_TYPE_OFFC', 'VIC_INC_MONTH', 'VIC_INC_DOW',\n",
      "       'NUM_STATE_CODE', 'STATE', 'POP_GROUP', 'CTRY_DIVISION', 'CTRY_REGION',\n",
      "       'CORE_CITY', 'CURRENT_POP1', 'lat', 'lng', 'density', 'military',\n",
      "       'incorporated', 'timezone', 'ranking', 'OFF_CODE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Remove irrelevant and redundant fields\n",
    "\n",
    "# Drop unneeded columns\n",
    "# KEEP STATE\n",
    "df.drop(['X1','id', 'county_fips', 'county_fips_all', 'Unnamed: 0', \n",
    "         'ORI', 'INC_NUM', 'NUM_RECS_PER_VICTIM', 'VIC_INC_DATE', 'VIC_INC_YEAR', 'VIC_INC_DAY',\n",
    "         'ASSAULT_CIRC1', 'ASSAULT_CIRC2', 'JUST_HOM_CIRC', \n",
    "         'INJURY_TYPE1', 'INJURY_TYPE2', 'INJURY_TYPE3',\n",
    "         'INJURY_TYPE4', 'INJURY_TYPE5', 'NUM_RECS_PER_VICTIM', 'AGENCY_IND',\n",
    "         'FBI_OFFICE', 'JUDICIAL_DIST', 'FIPS_COUNTY1',\n",
    "         'LAST_POP1', 'UCR_COUNTY_CD1', 'MSA_CD1', 'city_ascii', 'CITY',\n",
    "         'state_name', 'county_name', 'county_name_all', 'population', 'zips',\n",
    "         'source'], \n",
    "        axis=1, inplace = True)\n",
    "\n",
    "# Also removing victim demograohics since they are not relevant to predict offenses and locations\n",
    "df.drop(['VICTIM_TYPE','RACE_OF_VICTIM', 'AGE_OF_VICTIM', \n",
    "         'SEX_OF_VICTIM', 'ETHNIC_OF_VIC', 'VIC_RESIDENT'],\n",
    "        axis=1, inplace = True)\n",
    "\n",
    "# Verify Change\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NA values with NULL\n",
    "df.replace('NA', np.nan)\n",
    "\n",
    "# Remove Unknown Values with NULL\n",
    "df.replace('U', np.nan)\n",
    "\n",
    "# Drop columns with mostly NULL data\n",
    "df.drop(['ACT_TYPE_OFFC','ASSG_TYPE_OFFC'],\n",
    "        axis=1, inplace = True)\n",
    "\n",
    "# Drop records with remaining null values\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change DOW to numeric value\n",
    "def f_dow(df):\n",
    "    if df['VIC_INC_DOW'] == 'Sunday':\n",
    "        val = 1\n",
    "    elif df['VIC_INC_DOW'] == 'Monday':\n",
    "        val = 2\n",
    "    elif df['VIC_INC_DOW'] == 'Tuesday':\n",
    "        val = 3\n",
    "    elif df['VIC_INC_DOW'] == 'Wednesday':\n",
    "        val = 4\n",
    "    elif df['VIC_INC_DOW'] == 'Thursday':\n",
    "        val = 5\n",
    "    elif df['VIC_INC_DOW'] == 'Friday':\n",
    "        val = 6\n",
    "    elif df['VIC_INC_DOW'] == 'Saturday':\n",
    "        val = 7\n",
    "    else:\n",
    "        val=0\n",
    "    return val\n",
    "\n",
    "# Change Timezone to numeric value\n",
    "def f_tz(df):\n",
    "    if df['timezone'] == 'America/New_York':\n",
    "        val = 1\n",
    "    elif df['timezone'] == 'America/Detroit':\n",
    "        val = 2\n",
    "    elif df['timezone'] == 'America/Chicago':\n",
    "        val = 2\n",
    "    elif df['timezone'] == 'America/Denver':\n",
    "        val = 3\n",
    "    elif df['timezone'] == 'America/Los_Angeles':\n",
    "        val = 4\n",
    "    else:\n",
    "        val=0\n",
    "    return val\n",
    "\n",
    "def f_state(df):\n",
    "    if df['STATE'] == 'TN':\n",
    "        val = 1\n",
    "    elif df['STATE'] == 'MI':\n",
    "        val = 2\n",
    "    elif df['STATE'] == 'SC':\n",
    "        val = 3\n",
    "    elif df['STATE'] == 'MA':\n",
    "        val = 4\n",
    "    elif df['STATE'] == 'OH':\n",
    "        val = 5\n",
    "    elif df['STATE'] == 'WA':\n",
    "        val = 6\n",
    "    else:\n",
    "        val=0\n",
    "    return val\n",
    "\n",
    "# Convert simple categorical features to numeric to limit dummy features\n",
    "df['VIC_INC_DOW'] = df.apply(f_dow, axis=1)\n",
    "df['timezone'] = df.apply(f_tz, axis=1)\n",
    "df['STATE'] = df.apply(f_state, axis=1)\n",
    "\n",
    "df['CORE_CITY'] = df['CORE_CITY'].map({'Y': 1, 'N': 0})\n",
    "df['military'] = df['military'].map({True: 1, False: 0})\n",
    "df['incorporated'] = df['incorporated'].map({True: 1, False: 0})\n",
    "\n",
    "# Change target feature to easily translated numeric values\n",
    "def f_off(df):\n",
    "    if df['OFF_CODE'] == '09A':\n",
    "        val = 91\n",
    "    elif df['OFF_CODE'] == '09B':\n",
    "        val = 92\n",
    "    elif df['OFF_CODE'] == '09C':\n",
    "        val = 93\n",
    "    elif df['OFF_CODE'] == '100':\n",
    "        val = 100\n",
    "    elif df['OFF_CODE'] == '11A':\n",
    "        val = 111\n",
    "    elif df['OFF_CODE'] == '11B':\n",
    "        val = 112\n",
    "    elif df['OFF_CODE'] == '11C':\n",
    "        val = 113\n",
    "    elif df['OFF_CODE'] == '11D':\n",
    "        val = 114\n",
    "    elif df['OFF_CODE'] == '120':\n",
    "        val = 120\n",
    "    elif df['OFF_CODE'] == '13A':\n",
    "        val = 131\n",
    "    elif df['OFF_CODE'] == '13B':\n",
    "        val = 132\n",
    "    elif df['OFF_CODE'] == '13C':\n",
    "        val = 133\n",
    "    elif df['OFF_CODE'] == '200':\n",
    "        val = 200\n",
    "    elif df['OFF_CODE'] == '210':\n",
    "        val = 210\n",
    "    elif df['OFF_CODE'] == '220':\n",
    "        val = 220\n",
    "    elif df['OFF_CODE'] == '23A':\n",
    "        val = 231\n",
    "    elif df['OFF_CODE'] == '23B':\n",
    "        val = 232\n",
    "    elif df['OFF_CODE'] == '23C':\n",
    "        val = 233\n",
    "    elif df['OFF_CODE'] == '23D':\n",
    "        val = 234\n",
    "    elif df['OFF_CODE'] == '23E':\n",
    "        val = 235\n",
    "    elif df['OFF_CODE'] == '23F':\n",
    "        val = 236\n",
    "    elif df['OFF_CODE'] == '23G':\n",
    "        val = 237\n",
    "    elif df['OFF_CODE'] == '23H':\n",
    "        val = 238\n",
    "    elif df['OFF_CODE'] == '240':\n",
    "        val = 240\n",
    "    elif df['OFF_CODE'] == '250':\n",
    "        val = 250\n",
    "    elif df['OFF_CODE'] == '26A':\n",
    "        val = 261\n",
    "    elif df['OFF_CODE'] == '26B':\n",
    "        val = 262\n",
    "    elif df['OFF_CODE'] == '26C':\n",
    "        val = 263\n",
    "    elif df['OFF_CODE'] == '26D':\n",
    "        val = 264\n",
    "    elif df['OFF_CODE'] == '26E':\n",
    "        val = 265\n",
    "    elif df['OFF_CODE'] == '26F':\n",
    "        val = 266\n",
    "    elif df['OFF_CODE'] == '26G':\n",
    "        val = 267\n",
    "    elif df['OFF_CODE'] == '270':\n",
    "        val = 270\n",
    "    elif df['OFF_CODE'] == '280':\n",
    "        val = 280\n",
    "    elif df['OFF_CODE'] == '290':\n",
    "        val = 290\n",
    "    elif df['OFF_CODE'] == '35A':\n",
    "        val = 351\n",
    "    elif df['OFF_CODE'] == '35B':\n",
    "        val = 352\n",
    "    elif df['OFF_CODE'] == '36A':\n",
    "        val = 361\n",
    "    elif df['OFF_CODE'] == '36B':\n",
    "        val = 362\n",
    "    elif df['OFF_CODE'] == '370':\n",
    "        val = 370\n",
    "    elif df['OFF_CODE'] == '39A':\n",
    "        val = 391\n",
    "    elif df['OFF_CODE'] == '39B':\n",
    "        val = 392\n",
    "    elif df['OFF_CODE'] == '39C':\n",
    "        val = 393\n",
    "    elif df['OFF_CODE'] == '39D':\n",
    "        val = 394\n",
    "    elif df['OFF_CODE'] == '40A':\n",
    "        val = 401\n",
    "    elif df['OFF_CODE'] == '40B':\n",
    "        val = 402\n",
    "    elif df['OFF_CODE'] == '40C':\n",
    "        val = 403\n",
    "    elif df['OFF_CODE'] == '510':\n",
    "        val = 510\n",
    "    elif df['OFF_CODE'] == '520':\n",
    "        val = 520\n",
    "    elif df['OFF_CODE'] == '64A':\n",
    "        val = 641\n",
    "    elif df['OFF_CODE'] == '64B':\n",
    "        val = 642\n",
    "    elif df['OFF_CODE'] == '720':\n",
    "        val = 720\n",
    "    else:\n",
    "        val=0\n",
    "    return val  \n",
    "df['OFF_CODE'] = df.apply(f_off, axis=1)\n",
    "\n",
    "# Convert population group to easily translated numeric values\n",
    "def f_pop(df):\n",
    "    if df['POP_GROUP'] == '1A':\n",
    "        val = 11\n",
    "    elif df['POP_GROUP'] == '1B':\n",
    "        val = 12\n",
    "    elif df['POP_GROUP'] == '1C':\n",
    "        val = 13\n",
    "    elif df['POP_GROUP'] == '8A':\n",
    "        val = 81\n",
    "    elif df['POP_GROUP'] == '8B':\n",
    "        val = 82\n",
    "    elif df['POP_GROUP'] == '8C':\n",
    "        val = 83\n",
    "    elif df['POP_GROUP'] == '8D':\n",
    "        val = 84\n",
    "    elif df['POP_GROUP'] == '8E':\n",
    "        val = 85\n",
    "    elif df['POP_GROUP'] == '9A':\n",
    "        val = 91\n",
    "    elif df['POP_GROUP'] == '9B':\n",
    "        val = 92\n",
    "    elif df['POP_GROUP'] == '9C':\n",
    "        val = 93\n",
    "    elif df['POP_GROUP'] == '9D':\n",
    "        val = 94\n",
    "    elif df['POP_GROUP'] == '9E':\n",
    "        val = 95\n",
    "    else:\n",
    "        val=df['POP_GROUP']\n",
    "    return val  \n",
    "df['POP_GROUP'] = df.apply(f_pop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use offense code as the target variable.  The goal is to be able to predict offense code based on varying features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate datasets by state\n",
    "tn_df = df[df['STATE'] == 1]\n",
    "mi_df = df[df['STATE'] == 2]\n",
    "sc_df = df[df['STATE'] == 3]\n",
    "ma_df = df[df['STATE'] == 4]\n",
    "oh_df = df[df['STATE'] == 5]\n",
    "wa_df = df[df['STATE'] == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into two sets: Training and Testing.\n",
    "\n",
    "# Split out target variable\n",
    "tn_data_model_y = tn_df.OFF_CODE\n",
    "mi_data_model_y = mi_df.OFF_CODE\n",
    "sc_data_model_y = sc_df.OFF_CODE\n",
    "ma_data_model_y = ma_df.OFF_CODE\n",
    "oh_data_model_y = oh_df.OFF_CODE\n",
    "wa_data_model_y = wa_df.OFF_CODE\n",
    "\n",
    "# Remove target variable from feature list\n",
    "tn_data_model_X = tn_df.drop(['OFF_CODE'], axis=1, inplace = False)\n",
    "mi_data_model_X = mi_df.drop(['OFF_CODE'], axis=1, inplace = False)\n",
    "sc_data_model_X = sc_df.drop(['OFF_CODE'], axis=1, inplace = False)\n",
    "ma_data_model_X = ma_df.drop(['OFF_CODE'], axis=1, inplace = False)\n",
    "oh_data_model_X = oh_df.drop(['OFF_CODE'], axis=1, inplace = False)\n",
    "wa_data_model_X = wa_df.drop(['OFF_CODE'], axis=1, inplace = False)\n",
    "\n",
    "# Split the data into training and validation datasets\n",
    "# Save 30% for validation\n",
    "tn_X_train, tn_X_val, tn_y_train, tn_y_val = train_test_split(tn_data_model_X, tn_data_model_y, test_size =0.3, random_state=7)\n",
    "mi_X_train, mi_X_val, mi_y_train, mi_y_val = train_test_split(mi_data_model_X, mi_data_model_y, test_size =0.3, random_state=7)\n",
    "sc_X_train, sc_X_val, sc_y_train, sc_y_val = train_test_split(sc_data_model_X, sc_data_model_y, test_size =0.3, random_state=7)\n",
    "ma_X_train, ma_X_val, ma_y_train, ma_y_val = train_test_split(ma_data_model_X, ma_data_model_y, test_size =0.3, random_state=7)\n",
    "oh_X_train, oh_X_val, oh_y_train, oh_y_val = train_test_split(oh_data_model_X, oh_data_model_y, test_size =0.3, random_state=7)\n",
    "wa_X_train, wa_X_val, wa_y_train, wa_y_val = train_test_split(wa_data_model_X, wa_data_model_y, test_size =0.3, random_state=7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized Hyperparameters for each state\n",
    "#TN:  {'max_depth': 18, 'n_estimators': 445}\n",
    "#MI:  {'max_depth': 16, 'n_estimators': 186}\n",
    "#SC:  {'max_depth': 17, 'n_estimators': 284}\n",
    "#MA:  {'max_depth': 17, 'n_estimators': 293}\n",
    "#OH:  {'max_depth': 17, 'n_estimators': 284}\n",
    "#WA:  {'max_depth': 18, 'n_estimators': 484}\n",
    "\n",
    "# Create random forest classifer object\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "tn_rf_model = RandomForestClassifier(random_state=0, n_estimators=445, n_jobs=-1, max_depth=18, bootstrap=False)\n",
    "mi_rf_model = RandomForestClassifier(random_state=0, n_estimators=186, n_jobs=-1, max_depth=16, bootstrap=False)\n",
    "sc_rf_model = RandomForestClassifier(random_state=0, n_estimators=284, n_jobs=-1, max_depth=17, bootstrap=False)\n",
    "ma_rf_model = RandomForestClassifier(random_state=0, n_estimators=293, n_jobs=-1, max_depth=17, bootstrap=False)\n",
    "oh_rf_model = RandomForestClassifier(random_state=0, n_estimators=284, n_jobs=-1, max_depth=17, bootstrap=False)\n",
    "wa_rf_model = RandomForestClassifier(random_state=0, n_estimators=484, n_jobs=-1, max_depth=18, bootstrap=False)\n",
    "\n",
    "# Train model\n",
    "tn_forest = tn_rf_model.fit(tn_X_train, tn_y_train)\n",
    "mi_forest = mi_rf_model.fit(mi_X_train, mi_y_train)\n",
    "sc_forest = sc_rf_model.fit(sc_X_train, sc_y_train)\n",
    "ma_forest = ma_rf_model.fit(ma_X_train, ma_y_train)\n",
    "oh_forest = oh_rf_model.fit(oh_X_train, oh_y_train)\n",
    "wa_forest = wa_rf_model.fit(wa_X_train, wa_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values\n",
    "tn_y_pred_forest = tn_forest.predict(tn_X_val)\n",
    "mi_y_pred_forest = mi_forest.predict(mi_X_val)\n",
    "sc_y_pred_forest = sc_forest.predict(sc_X_val)\n",
    "ma_y_pred_forest = ma_forest.predict(ma_X_val)\n",
    "oh_y_pred_forest = oh_forest.predict(oh_X_val)\n",
    "wa_y_pred_forest = wa_forest.predict(wa_X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          91       0.00      0.00      0.00        52\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.00      0.00      0.00         6\n",
      "         100       0.22      0.05      0.08       323\n",
      "         111       0.18      0.01      0.03       267\n",
      "         112       0.86      0.79      0.82       154\n",
      "         113       0.00      0.00      0.00        28\n",
      "         114       0.48      0.11      0.18       366\n",
      "         120       0.25      0.23      0.24      2027\n",
      "         131       0.31      0.38      0.34      6936\n",
      "         132       0.22      0.54      0.31     14417\n",
      "         133       0.22      0.31      0.26      4151\n",
      "         200       0.12      0.11      0.12       151\n",
      "         210       0.00      0.00      0.00        48\n",
      "         220       0.23      0.21      0.22      6810\n",
      "         231       0.00      0.00      0.00        46\n",
      "         232       0.00      0.00      0.00        28\n",
      "         233       0.17      0.17      0.17      7623\n",
      "         234       0.20      0.07      0.11      4794\n",
      "         235       0.00      0.00      0.00        51\n",
      "         236       0.22      0.20      0.21      5673\n",
      "         237       0.17      0.01      0.01      1127\n",
      "         238       0.22      0.09      0.12      4622\n",
      "         240       0.14      0.01      0.02      2110\n",
      "         250       0.42      0.21      0.28      2744\n",
      "         261       0.18      0.08      0.11      3321\n",
      "         262       0.44      0.37      0.40      3904\n",
      "         263       0.27      0.03      0.06      1263\n",
      "         264       0.00      0.00      0.00        12\n",
      "         265       0.24      0.07      0.10       120\n",
      "         266       0.14      0.03      0.05       468\n",
      "         267       0.00      0.00      0.00         3\n",
      "         270       0.56      0.11      0.19       575\n",
      "         280       0.75      0.52      0.61       827\n",
      "         290       0.23      0.21      0.22      9008\n",
      "         351       0.16      0.13      0.14      7945\n",
      "         352       0.10      0.04      0.05      5373\n",
      "         361       0.00      0.00      0.00         5\n",
      "         362       0.33      0.04      0.08        67\n",
      "         370       0.00      0.00      0.00       103\n",
      "         391       0.00      0.00      0.00         1\n",
      "         392       0.00      0.00      0.00         3\n",
      "         393       0.00      0.00      0.00         5\n",
      "         401       0.00      0.00      0.00        83\n",
      "         402       0.00      0.00      0.00        17\n",
      "         403       0.25      0.25      0.25        12\n",
      "         510       0.00      0.00      0.00         6\n",
      "         520       0.04      0.00      0.00      1504\n",
      "         641       0.00      0.00      0.00         1\n",
      "         720       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.23     99220\n",
      "   macro avg       0.17      0.11      0.12     99220\n",
      "weighted avg       0.23      0.23      0.21     99220\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          91       0.24      0.05      0.08        85\n",
      "          92       0.00      0.00      0.00         5\n",
      "          93       0.00      0.00      0.00         1\n",
      "         100       0.42      0.12      0.18       186\n",
      "         111       0.18      0.01      0.02       603\n",
      "         112       0.27      0.03      0.05       271\n",
      "         113       0.00      0.00      0.00       106\n",
      "         114       0.41      0.12      0.18       791\n",
      "         120       0.27      0.15      0.19      1813\n",
      "         131       0.29      0.30      0.30      6132\n",
      "         132       0.23      0.62      0.34     16586\n",
      "         133       0.20      0.12      0.15      3829\n",
      "         200       0.38      0.22      0.28       392\n",
      "         210       0.33      0.02      0.03        64\n",
      "         220       0.26      0.25      0.25      8057\n",
      "         231       0.33      0.01      0.01       159\n",
      "         232       0.08      0.01      0.02       100\n",
      "         233       0.21      0.20      0.21      5534\n",
      "         234       0.23      0.07      0.11      3768\n",
      "         235       0.08      0.06      0.07        36\n",
      "         236       0.42      0.31      0.36      6474\n",
      "         237       0.30      0.04      0.07      1135\n",
      "         238       0.21      0.12      0.16      8029\n",
      "         240       0.17      0.02      0.03      2408\n",
      "         250       0.22      0.03      0.05       938\n",
      "         261       0.28      0.12      0.17      3589\n",
      "         262       0.29      0.12      0.17      2235\n",
      "         263       0.21      0.10      0.13      1020\n",
      "         264       0.00      0.00      0.00        20\n",
      "         265       0.11      0.01      0.01       147\n",
      "         266       0.27      0.22      0.24      1602\n",
      "         267       0.31      0.26      0.29        19\n",
      "         270       0.44      0.04      0.08       604\n",
      "         280       0.49      0.35      0.40      1336\n",
      "         290       0.28      0.22      0.25     10833\n",
      "         351       0.16      0.14      0.15      7580\n",
      "         352       0.05      0.01      0.01      2027\n",
      "         361       0.00      0.00      0.00         5\n",
      "         362       0.00      0.00      0.00         9\n",
      "         370       0.00      0.00      0.00       120\n",
      "         391       0.00      0.00      0.00         4\n",
      "         392       0.00      0.00      0.00         3\n",
      "         401       0.00      0.00      0.00        65\n",
      "         402       0.00      0.00      0.00        18\n",
      "         403       0.00      0.00      0.00         2\n",
      "         510       0.00      0.00      0.00         4\n",
      "         520       0.05      0.00      0.00      1593\n",
      "         641       0.30      1.00      0.46        22\n",
      "         642       0.00      0.00      0.00         2\n",
      "         720       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.25    100392\n",
      "   macro avg       0.18      0.11      0.11    100392\n",
      "weighted avg       0.25      0.25      0.22    100392\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          91       0.09      0.05      0.06        60\n",
      "          92       0.00      0.00      0.00         1\n",
      "          93       0.00      0.00      0.00         7\n",
      "         100       0.34      0.13      0.19       297\n",
      "         111       0.10      0.01      0.01       265\n",
      "         112       0.27      0.10      0.15        58\n",
      "         113       0.00      0.00      0.00        26\n",
      "         114       0.27      0.07      0.11       247\n",
      "         120       0.29      0.23      0.26      1960\n",
      "         131       0.34      0.38      0.36      4840\n",
      "         132       0.24      0.53      0.33     11305\n",
      "         133       0.23      0.09      0.13      2397\n",
      "         200       0.49      0.24      0.32       119\n",
      "         210       0.05      0.11      0.07        18\n",
      "         220       0.31      0.29      0.30      6300\n",
      "         231       0.27      0.39      0.32        51\n",
      "         232       0.00      0.00      0.00        30\n",
      "         233       0.16      0.12      0.13      5925\n",
      "         234       0.15      0.06      0.09      1699\n",
      "         235       0.00      0.00      0.00        71\n",
      "         236       0.27      0.38      0.32      7205\n",
      "         237       0.37      0.05      0.09       778\n",
      "         238       0.22      0.19      0.20      6743\n",
      "         240       0.12      0.02      0.03      1847\n",
      "         250       0.22      0.07      0.11      1557\n",
      "         261       0.40      0.12      0.19      2307\n",
      "         262       0.29      0.12      0.17      1620\n",
      "         263       0.65      0.24      0.36       757\n",
      "         264       0.00      0.00      0.00         7\n",
      "         265       0.40      0.06      0.10       136\n",
      "         266       0.00      0.00      0.00         7\n",
      "         270       0.81      0.50      0.62       505\n",
      "         280       0.26      0.14      0.18       939\n",
      "         290       0.22      0.24      0.23      9068\n",
      "         351       0.17      0.15      0.16      6352\n",
      "         352       0.10      0.03      0.04      2114\n",
      "         361       0.00      0.00      0.00         1\n",
      "         362       0.38      0.15      0.21        20\n",
      "         370       0.00      0.00      0.00        54\n",
      "         391       0.00      0.00      0.00         2\n",
      "         392       0.00      0.00      0.00         1\n",
      "         393       0.00      0.00      0.00         6\n",
      "         401       0.00      0.00      0.00       101\n",
      "         402       0.00      0.00      0.00         5\n",
      "         403       0.00      0.00      0.00        26\n",
      "         510       0.00      0.00      0.00         2\n",
      "         520       0.06      0.01      0.01      1572\n",
      "         641       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.25     79410\n",
      "   macro avg       0.18      0.11      0.12     79410\n",
      "weighted avg       0.24      0.25      0.23     79410\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          91       0.50      0.03      0.05        37\n",
      "          92       0.00      0.00      0.00         2\n",
      "         100       0.30      0.08      0.13       172\n",
      "         111       0.50      0.01      0.01       272\n",
      "         112       0.59      0.15      0.24       106\n",
      "         113       0.00      0.00      0.00         8\n",
      "         114       0.14      0.02      0.04       213\n",
      "         120       0.20      0.09      0.13      1802\n",
      "         131       0.23      0.19      0.21      5144\n",
      "         132       0.24      0.54      0.33     10065\n",
      "         133       0.25      0.11      0.15      3264\n",
      "         200       0.49      0.47      0.48       265\n",
      "         210       0.00      0.00      0.00        33\n",
      "         220       0.23      0.26      0.24      5808\n",
      "         231       0.00      0.00      0.00       162\n",
      "         232       0.00      0.00      0.00        44\n",
      "         233       0.22      0.05      0.08      2431\n",
      "         234       0.25      0.08      0.12      1763\n",
      "         235       0.00      0.00      0.00         7\n",
      "         236       0.30      0.19      0.23      3826\n",
      "         237       0.05      0.00      0.00       507\n",
      "         238       0.36      0.38      0.37      7788\n",
      "         240       0.14      0.01      0.02      1458\n",
      "         250       0.16      0.03      0.06       587\n",
      "         261       0.32      0.07      0.12      1675\n",
      "         262       0.25      0.10      0.15       912\n",
      "         263       0.50      0.19      0.28      1021\n",
      "         264       0.00      0.00      0.00         6\n",
      "         265       0.00      0.00      0.00        25\n",
      "         266       0.00      0.00      0.00       125\n",
      "         267       0.00      0.00      0.00         6\n",
      "         270       0.50      0.26      0.34       149\n",
      "         280       0.30      0.18      0.23       682\n",
      "         290       0.31      0.42      0.36      9959\n",
      "         351       0.08      0.00      0.01      1973\n",
      "         352       0.00      0.00      0.00        32\n",
      "         361       0.00      0.00      0.00         3\n",
      "         362       0.09      0.03      0.05        98\n",
      "         370       0.00      0.00      0.00        77\n",
      "         392       0.00      0.00      0.00         5\n",
      "         401       0.00      0.00      0.00        96\n",
      "         402       0.00      0.00      0.00        14\n",
      "         403       0.00      0.00      0.00         2\n",
      "         510       0.00      0.00      0.00         1\n",
      "         520       0.00      0.00      0.00       996\n",
      "         720       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.27     63622\n",
      "   macro avg       0.16      0.09      0.10     63622\n",
      "weighted avg       0.26      0.27      0.24     63622\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          91       0.33      0.02      0.04        89\n",
      "         100       0.30      0.22      0.25       407\n",
      "         111       0.33      0.01      0.02       515\n",
      "         112       0.10      0.02      0.03        54\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.34      0.12      0.18       438\n",
      "         120       0.25      0.15      0.19      1886\n",
      "         131       0.31      0.12      0.18      2146\n",
      "         132       0.23      0.42      0.30     11997\n",
      "         133       0.25      0.37      0.30      9479\n",
      "         200       0.28      0.30      0.29       398\n",
      "         210       0.00      0.00      0.00        37\n",
      "         220       0.25      0.23      0.24      9740\n",
      "         231       0.23      0.04      0.06       170\n",
      "         232       0.06      0.01      0.01       164\n",
      "         233       0.23      0.21      0.22      5960\n",
      "         234       0.31      0.15      0.20      4092\n",
      "         235       0.33      0.06      0.10        36\n",
      "         236       0.33      0.24      0.28      6436\n",
      "         237       0.11      0.00      0.00       433\n",
      "         238       0.23      0.33      0.27     11224\n",
      "         240       0.14      0.02      0.03      1693\n",
      "         250       0.30      0.06      0.10      1251\n",
      "         261       0.19      0.02      0.04       998\n",
      "         262       0.23      0.03      0.05       899\n",
      "         263       0.30      0.16      0.21      1464\n",
      "         264       0.60      0.09      0.16        32\n",
      "         265       0.00      0.00      0.00         5\n",
      "         266       0.00      0.00      0.00       221\n",
      "         270       0.00      0.00      0.00        10\n",
      "         280       0.55      0.29      0.38      1897\n",
      "         290       0.28      0.35      0.31     12968\n",
      "         351       0.17      0.12      0.14      7403\n",
      "         352       0.12      0.04      0.06      5541\n",
      "         361       0.00      0.00      0.00         4\n",
      "         362       1.00      0.02      0.05        41\n",
      "         370       0.00      0.00      0.00       172\n",
      "         392       0.00      0.00      0.00         5\n",
      "         401       0.00      0.00      0.00        17\n",
      "         402       0.09      0.01      0.02       108\n",
      "         510       0.00      0.00      0.00         2\n",
      "         520       0.19      0.01      0.02      1324\n",
      "\n",
      "    accuracy                           0.25    101757\n",
      "   macro avg       0.21      0.10      0.11    101757\n",
      "weighted avg       0.25      0.25      0.23    101757\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          91       0.44      0.19      0.27        58\n",
      "          92       0.00      0.00      0.00         4\n",
      "          93       0.00      0.00      0.00         3\n",
      "         100       0.36      0.03      0.05       361\n",
      "         111       0.39      0.04      0.08       521\n",
      "         112       0.00      0.00      0.00        46\n",
      "         113       0.00      0.00      0.00        19\n",
      "         114       0.31      0.05      0.09       635\n",
      "         120       0.30      0.11      0.17      1998\n",
      "         131       0.31      0.14      0.19      3420\n",
      "         132       0.23      0.19      0.21     11284\n",
      "         133       0.60      0.34      0.44      3364\n",
      "         200       0.45      0.25      0.32       399\n",
      "         210       0.00      0.00      0.00        44\n",
      "         220       0.28      0.25      0.26     13304\n",
      "         231       0.50      0.07      0.12       103\n",
      "         232       0.26      0.02      0.04       258\n",
      "         233       0.19      0.15      0.17      7935\n",
      "         234       0.33      0.13      0.19      3245\n",
      "         235       0.00      0.00      0.00        34\n",
      "         236       0.46      0.50      0.48     19899\n",
      "         237       0.31      0.15      0.20      1414\n",
      "         238       0.43      0.60      0.50     25196\n",
      "         240       0.19      0.04      0.07      6324\n",
      "         250       0.49      0.23      0.32      3401\n",
      "         261       0.40      0.26      0.31      2083\n",
      "         262       0.74      0.54      0.63      2767\n",
      "         263       0.50      0.39      0.44      2533\n",
      "         264       0.00      0.00      0.00        11\n",
      "         265       0.78      0.10      0.18        68\n",
      "         266       0.26      0.10      0.14      1739\n",
      "         267       0.00      0.00      0.00        14\n",
      "         270       0.72      0.67      0.70       309\n",
      "         280       0.61      0.62      0.61      8519\n",
      "         290       0.24      0.47      0.32     20381\n",
      "         351       0.10      0.02      0.03      4896\n",
      "         352       0.09      0.03      0.05      2485\n",
      "         361       0.31      0.18      0.23        22\n",
      "         362       0.00      0.00      0.00        63\n",
      "         370       0.00      0.00      0.00       115\n",
      "         392       0.00      0.00      0.00         1\n",
      "         401       0.00      0.00      0.00        72\n",
      "         402       0.00      0.00      0.00        18\n",
      "         403       0.00      0.00      0.00        12\n",
      "         520       0.04      0.00      0.00      1358\n",
      "         641       0.00      0.00      0.00         9\n",
      "         720       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.36    150760\n",
      "   macro avg       0.25      0.15      0.17    150760\n",
      "weighted avg       0.35      0.36      0.33    150760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create classification report\n",
    "print(classification_report(tn_y_val, tn_y_pred_forest))\n",
    "print(classification_report(mi_y_val, mi_y_pred_forest))\n",
    "print(classification_report(sc_y_val, sc_y_pred_forest))\n",
    "print(classification_report(ma_y_val, ma_y_pred_forest))\n",
    "print(classification_report(oh_y_val, oh_y_pred_forest))\n",
    "print(classification_report(wa_y_val, wa_y_pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN:  {'max_depth': 18, 'n_estimators': 445}\n",
      "MI:  {'max_depth': 16, 'n_estimators': 186}\n",
      "SC:  {'max_depth': 17, 'n_estimators': 284}\n",
      "MA:  {'max_depth': 17, 'n_estimators': 293}\n",
      "OH:  {'max_depth': 17, 'n_estimators': 284}\n",
      "WA:  {'max_depth': 18, 'n_estimators': 484}\n"
     ]
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# https://jamesrledoux.com/code/randomized_parameter_search\n",
    "\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "#from scipy.stats import randint\n",
    "\n",
    "#model_params = {\n",
    "#    'n_estimators': randint(10,500),\n",
    "#    'max_depth': randint(1,50)\n",
    "#}\n",
    "\n",
    "# First create the base model to tune\n",
    "#rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "#tn_rf_random = RandomizedSearchCV(rf, model_params, n_iter=100, cv=3, random_state=3, n_jobs = -1)\n",
    "#mi_rf_random = RandomizedSearchCV(rf, model_params, n_iter=100, cv=3, random_state=3, n_jobs = -1)\n",
    "#sc_rf_random = RandomizedSearchCV(rf, model_params, n_iter=100, cv=3, random_state=3, n_jobs = -1)\n",
    "#ma_rf_random = RandomizedSearchCV(rf, model_params, n_iter=100, cv=3, random_state=3, n_jobs = -1)\n",
    "#oh_rf_random = RandomizedSearchCV(rf, model_params, n_iter=100, cv=3, random_state=3, n_jobs = -1)\n",
    "#wa_rf_random = RandomizedSearchCV(rf, model_params, n_iter=100, cv=3, random_state=3, n_jobs = -1)\n",
    "\n",
    "#tn_rf_random.fit(tn_X_train, tn_y_train)\n",
    "#mi_rf_random.fit(mi_X_train, mi_y_train)\n",
    "#sc_rf_random.fit(sc_X_train, sc_y_train)\n",
    "#ma_rf_random.fit(ma_X_train, ma_y_train)\n",
    "#oh_rf_random.fit(oh_X_train, oh_y_train)\n",
    "#wa_rf_random.fit(wa_X_train, wa_y_train)\n",
    "\n",
    "#print('TN: ', tn_rf_random.best_params_)\n",
    "#print('MI: ', mi_rf_random.best_params_)\n",
    "#print('SC: ', sc_rf_random.best_params_)\n",
    "#print('MA: ', ma_rf_random.best_params_)\n",
    "#print('OH: ', oh_rf_random.best_params_)\n",
    "#print('WA: ', wa_rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of model hyperparameter assessments:\n",
    "\n",
    "TN:  {'max_depth': 18, 'n_estimators': 445\n",
    "\n",
    "MI:  {'max_depth': 16, 'n_estimators': 186}\n",
    "\n",
    "SC:  {'max_depth': 17, 'n_estimators': 284}\n",
    "\n",
    "MA:  {'max_depth': 17, 'n_estimators': 293}\n",
    "\n",
    "OH:  {'max_depth': 17, 'n_estimators': 284}\n",
    "\n",
    "WA:  {'max_depth': 18, 'n_estimators': 484}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find most important features in Random Forest model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate feature importances\n",
    "tn_importances = tn_forest.feature_importances_\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(tn_importances)[::-1]\n",
    "\n",
    "# Rearrange feature names so they match the sorted feature importances\n",
    "tn_names = [tn_X_train.columns[i] for i in indices]\n",
    "\n",
    "# Create plot\n",
    "plt.figure()\n",
    "\n",
    "# Create plot title\n",
    "plt.title(\"Feature Importance\")\n",
    "\n",
    "# Add bars\n",
    "plt.bar(range(tn_X_train.shape[1]), tn_importances[indices])\n",
    "\n",
    "# Add feature names as x-axis labels\n",
    "plt.xticks(range(tn_X_train.shape[1]), tn_names, rotation=90)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          91       0.00      0.00      0.00        52\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.00      0.00      0.00         6\n",
      "         100       0.19      0.05      0.08       323\n",
      "         111       0.18      0.01      0.03       267\n",
      "         112       0.86      0.79      0.82       154\n",
      "         113       0.00      0.00      0.00        28\n",
      "         114       0.48      0.11      0.18       366\n",
      "         120       0.25      0.23      0.24      2027\n",
      "         131       0.31      0.38      0.34      6936\n",
      "         132       0.22      0.55      0.31     14417\n",
      "         133       0.22      0.31      0.26      4151\n",
      "         200       0.12      0.11      0.11       151\n",
      "         210       0.00      0.00      0.00        48\n",
      "         220       0.23      0.21      0.22      6810\n",
      "         231       0.00      0.00      0.00        46\n",
      "         232       0.00      0.00      0.00        28\n",
      "         233       0.17      0.17      0.17      7623\n",
      "         234       0.20      0.07      0.11      4794\n",
      "         235       0.00      0.00      0.00        51\n",
      "         236       0.23      0.20      0.21      5673\n",
      "         237       0.19      0.01      0.01      1127\n",
      "         238       0.22      0.09      0.12      4622\n",
      "         240       0.15      0.01      0.02      2110\n",
      "         250       0.42      0.21      0.28      2744\n",
      "         261       0.19      0.08      0.11      3321\n",
      "         262       0.44      0.37      0.40      3904\n",
      "         263       0.27      0.03      0.06      1263\n",
      "         264       0.00      0.00      0.00        12\n",
      "         265       0.23      0.07      0.10       120\n",
      "         266       0.15      0.03      0.05       468\n",
      "         267       0.00      0.00      0.00         3\n",
      "         270       0.56      0.11      0.19       575\n",
      "         280       0.75      0.52      0.61       827\n",
      "         290       0.23      0.21      0.22      9008\n",
      "         351       0.16      0.13      0.14      7945\n",
      "         352       0.10      0.04      0.05      5373\n",
      "         361       0.00      0.00      0.00         5\n",
      "         362       0.33      0.04      0.08        67\n",
      "         370       0.00      0.00      0.00       103\n",
      "         391       0.00      0.00      0.00         1\n",
      "         392       0.00      0.00      0.00         3\n",
      "         393       0.00      0.00      0.00         5\n",
      "         401       0.00      0.00      0.00        83\n",
      "         402       0.00      0.00      0.00        17\n",
      "         403       0.25      0.25      0.25        12\n",
      "         510       0.00      0.00      0.00         6\n",
      "         520       0.04      0.00      0.00      1504\n",
      "         641       0.00      0.00      0.00         1\n",
      "         720       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.23     99220\n",
      "   macro avg       0.17      0.11      0.12     99220\n",
      "weighted avg       0.23      0.23      0.21     99220\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amomu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Re-run random forest, limiting to important features \n",
    "\n",
    "# Drop features w/ little importance\n",
    "tn_data_model_X.drop(['CTRY_DIVISION', 'CTRY_REGION', 'military', 'incorporated', 'STATE', 'NUM_STATE_CODE'],\n",
    "                  axis=1, inplace = True)\n",
    "\n",
    "# Split the data into training and validation datasets\n",
    "# Save 30% for validation\n",
    "tn_X_train, tn_X_val, tn_y_train, tn_y_val = train_test_split(tn_data_model_X, tn_data_model_y, test_size =0.3, random_state=7)\n",
    "\n",
    "tn_rf_model = RandomForestClassifier(random_state=0, n_estimators=445, n_jobs=-1, max_depth=18, bootstrap=False)\n",
    "tn_forest = tn_rf_model.fit(tn_X_train, tn_y_train)\n",
    "tn_y_pred_forest = tn_forest.predict(tn_X_val)\n",
    "print(classification_report(tn_y_val, tn_y_pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
